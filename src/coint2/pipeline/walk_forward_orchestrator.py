"""Walk-forward analysis orchestrator."""

from __future__ import annotations

import pandas as pd

from coint2.core import math_utils, performance
from coint2.core.data_loader import DataHandler
from coint2.engine.backtest_engine import PairBacktester
from coint2.utils.config import AppConfig
from coint2.utils.logging_utils import get_logger
from coint2.utils.visualization import (
    create_performance_report, 
    format_metrics_summary, 
    calculate_extended_metrics
)
from pathlib import Path


def run_walk_forward(cfg: AppConfig) -> dict[str, float]:
    """Run walk-forward analysis and return aggregated performance metrics."""
    logger = get_logger("walk_forward")

    handler = DataHandler(cfg)
    handler.clear_cache()

    start_date = pd.to_datetime(cfg.walk_forward.start_date)
    end_date = pd.to_datetime(cfg.walk_forward.end_date)

    full_range_start = start_date - pd.Timedelta(days=cfg.walk_forward.training_period_days)
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ {full_range_start} - {end_date}")
    master_df = handler.preload_all_data(full_range_start, end_date)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {master_df.shape}, —Å–∏–º–≤–æ–ª–æ–≤: {len(master_df.columns)}")

    current_date = start_date
    aggregated_pnl = pd.Series(dtype=float)
    daily_pnl = []
    equity_data = []
    pair_count_data = []
    trade_stats = []  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º

    equity = cfg.portfolio.initial_capital
    equity_curve = [equity]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É –≤ equity_data
    equity_data.append((start_date, equity))

    while current_date < end_date:
        training_start = current_date
        training_end = training_start + pd.Timedelta(
            days=cfg.walk_forward.training_period_days
        )

        testing_start = training_end
        testing_end = testing_start + pd.Timedelta(
            days=cfg.walk_forward.testing_period_days
        )

        if testing_end > end_date:
            break

        training_slice = master_df.loc[training_start:training_end]
        logger.debug(f"Training slice –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ {training_start}-{training_end}: {training_slice.shape}")
        
        if training_slice.empty or len(training_slice.columns) < 2:
            logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: –ø—É—Å—Ç–æ–π slice –∏–ª–∏ < 2 —Å–∏–º–≤–æ–ª–æ–≤")
            pairs: list[tuple[str, str, float, float, float]] = []
        else:
            logger.debug(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(training_slice.columns)} —Å–∏–º–≤–æ–ª–æ–≤")
            normalized_training = (training_slice - training_slice.min()) / (
                training_slice.max() - training_slice.min()
            )
            # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å NaN (–∫–æ–≥–¥–∞ min == max, –¥–µ–ª–µ–Ω–∏–µ –¥–∞–µ—Ç NaN)
            normalized_training = normalized_training.dropna(axis=1)
            logger.debug(f"–ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(normalized_training.columns)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            if len(normalized_training.columns) < 2:
                logger.warning("–ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω–µ–µ 2 —Å–∏–º–≤–æ–ª–æ–≤")
                pairs = []
            else:
                logger.debug(f"–†–∞—Å—á–µ—Ç SSD –¥–ª—è top-{cfg.pair_selection.ssd_top_n} –ø–∞—Ä")
                ssd = math_utils.calculate_ssd(
                    normalized_training, top_k=cfg.pair_selection.ssd_top_n
                )
                logger.debug(f"SSD —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –¥–ª—è {len(ssd)} –ø–∞—Ä")
                
                pairs = []
                for s1, s2 in ssd.index:
                    pair_train = training_slice[[s1, s2]].dropna()
                    if pair_train.empty or pair_train[s2].var() == 0:
                        continue
                    beta = pair_train[s1].cov(pair_train[s2]) / pair_train[s2].var()
                    spread = pair_train[s1] - beta * pair_train[s2]
                    mean = spread.mean()
                    std = spread.std()
                    pairs.append((s1, s2, beta, mean, std))
                
                logger.debug(f"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ {len(pairs)} –ø–∞—Ä –ø–æ—Å–ª–µ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫")

        logger.info(
            "Walk-forward step train %s-%s, test %s-%s, %d pairs",
            training_start.date(),
            training_end.date(),
            testing_start.date(),
            testing_end.date(),
            len(pairs),
        )

        sorted_pairs = sorted(pairs)
        active_pairs = sorted_pairs[: cfg.portfolio.max_active_positions]

        step_pnl = pd.Series(dtype=float)
        total_step_pnl = 0.0

        if active_pairs:
            capital_per_pair = equity * cfg.portfolio.risk_per_position_pct
        else:
            capital_per_pair = 0.0

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á–µ—Ç–∞
        period_label = f"{training_start.strftime('%m/%d')}-{testing_end.strftime('%m/%d')}"
        pair_count_data.append((period_label, len(active_pairs)))

        for s1, s2, beta, mean, std in active_pairs:
            pair_data = master_df.loc[testing_start:testing_end, [s1, s2]].dropna()
            bt = PairBacktester(
                pair_data,
                beta=beta,
                spread_mean=mean,
                spread_std=std,
                z_threshold=cfg.backtest.zscore_threshold,
                commission_pct=cfg.backtest.commission_pct,
                slippage_pct=cfg.backtest.slippage_pct,
                annualizing_factor=cfg.backtest.annualizing_factor,
            )
            bt.run()
            results = bt.get_results()
            pnl_series = results["pnl"] * capital_per_pair
            step_pnl = step_pnl.add(pnl_series, fill_value=0)
            total_step_pnl += pnl_series.sum()
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–¥–µ–ª–∫–∞–º –¥–ª—è –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—ã
            if isinstance(results, dict):
                trades = results.get("trades", pd.Series())
                positions = results.get("position", pd.Series())
                costs = results.get("costs", pd.Series())
            else:
                # –ï—Å–ª–∏ results - DataFrame, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
                trades = results.get("trades", results.get("trades", pd.Series()))
                positions = results.get("position", results.get("position", pd.Series()))
                costs = results.get("costs", results.get("costs", pd.Series()))
            
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç–∏–π/–∑–∞–∫—Ä—ã—Ç–∏–π –ø–æ–∑–∏—Ü–∏–π
            if not positions.empty:
                position_changes = positions.diff().fillna(0).abs()
                trade_opens = (position_changes > 0).sum()
            else:
                trade_opens = 0
            
            # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–∞—Ä–∞–º, –¥–∞–∂–µ –µ—Å–ª–∏ —Å–¥–µ–ª–æ–∫ –Ω–µ –±—ã–ª–æ
            pair_pnl = pnl_series.sum()
            pair_costs = costs.sum() if not costs.empty else 0
            
            trade_stats.append({
                'pair': f'{s1}-{s2}',
                'period': period_label,
                'total_pnl': pair_pnl,
                'total_costs': pair_costs,
                'trade_count': trade_opens,
                'avg_pnl_per_trade': pair_pnl / max(trade_opens, 1),
                'win_days': (pnl_series > 0).sum(),
                'lose_days': (pnl_series < 0).sum(),
                'total_days': len(pnl_series),
                'max_daily_gain': pnl_series.max(),
                'max_daily_loss': pnl_series.min()
            })

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–Ω–µ–≤–Ω–æ–π P&L –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞
        if not step_pnl.empty:
            running_equity = equity
            for date, pnl in step_pnl.items():
                daily_pnl.append((date, pnl))
                running_equity += pnl
                equity_data.append((date, running_equity))

        aggregated_pnl = pd.concat([aggregated_pnl, step_pnl])
        equity += total_step_pnl
        equity_curve.append(equity)

        current_date = testing_end

    aggregated_pnl = aggregated_pnl.dropna()
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    if daily_pnl:
        dates, pnls = zip(*daily_pnl)
        pnl_series = pd.Series(pnls, index=pd.to_datetime(dates))
        pnl_series = pnl_series.groupby(pnl_series.index.date).sum()  # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        pnl_series.index = pd.to_datetime(pnl_series.index)
    else:
        pnl_series = pd.Series(dtype=float)
    
    if equity_data:
        eq_dates, eq_values = zip(*equity_data)
        equity_series = pd.Series(eq_values, index=pd.to_datetime(eq_dates))
    else:
        equity_series = pd.Series([cfg.portfolio.initial_capital])
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if aggregated_pnl.empty:
        base_metrics = {"sharpe_ratio": 0.0, "max_drawdown": 0.0, "total_pnl": 0.0}
    else:
        cumulative = aggregated_pnl.cumsum()
        base_metrics = {
            "sharpe_ratio": performance.sharpe_ratio(
                aggregated_pnl, cfg.backtest.annualizing_factor
            ),
            "max_drawdown": performance.max_drawdown(cumulative),
            "total_pnl": cumulative.iloc[-1] if not cumulative.empty else 0.0,
        }
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    extended_metrics = calculate_extended_metrics(pnl_series, equity_series)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º
    trade_metrics = {}
    if trade_stats:
        trades_df = pd.DataFrame(trade_stats)
        trade_metrics = {
            'total_trades': trades_df['trade_count'].sum(),
            'total_pairs_traded': len(trades_df['pair'].unique()),
            'total_costs': trades_df['total_costs'].sum(),
            'avg_trades_per_pair': trades_df['trade_count'].mean(),
            'win_rate_trades': trades_df['win_days'].sum() / max(trades_df['total_days'].sum(), 1),
            'best_pair_pnl': trades_df['total_pnl'].max(),
            'worst_pair_pnl': trades_df['total_pnl'].min(),
            'avg_pnl_per_pair': trades_df['total_pnl'].mean(),
        }
    
    all_metrics = {**base_metrics, **extended_metrics, **trade_metrics}
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç—ã
    results_dir = Path(cfg.results_dir)
    
    try:
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        create_performance_report(
            equity_curve=equity_series,
            pnl_series=pnl_series,
            metrics=all_metrics,
            pair_counts=pair_count_data,
            results_dir=results_dir,
            strategy_name="CointegrationStrategy"
        )
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Å–∏–≤—ã–µ –∏—Ç–æ–≥–∏
        summary = format_metrics_summary(all_metrics)
        print(summary)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV
        metrics_df = pd.DataFrame([all_metrics])
        metrics_df.to_csv(results_dir / "strategy_metrics.csv", index=False)
        print(f"üìã –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_dir / 'strategy_metrics.csv'}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
        if not pnl_series.empty:
            pnl_series.to_csv(results_dir / "daily_pnl.csv", header=['PnL'])
            print(f"üìà –î–Ω–µ–≤–Ω—ã–µ P&L —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_dir / 'daily_pnl.csv'}")
        
        if not equity_series.empty:
            equity_series.to_csv(results_dir / "equity_curve.csv", header=['Equity'])
            print(f"üí∞ –ö—Ä–∏–≤–∞—è –∫–∞–ø–∏—Ç–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {results_dir / 'equity_curve.csv'}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–¥–µ–ª–∫–∞–º
        if trade_stats:
            trades_df = pd.DataFrame(trade_stats)
            trades_df.to_csv(results_dir / "trade_statistics.csv", index=False)
            print(f"üîÑ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {results_dir / 'trade_statistics.csv'}")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ—Ç—á–µ—Ç–æ–≤: {e}")
    
    return base_metrics
